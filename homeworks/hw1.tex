\documentclass[11pt]{article}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{epsfig}
\def\shownotes{1}
\usepackage{source_files/macro}
\usepackage{url}
\usepackage{mdframed}
\usepackage[noend,noline]{algorithm2e}
%\usepackage{enumerate,enumitem}
\SetEndCharOfAlgoLine{}
\SetArgSty{}
\SetKwBlock{Repeat}{repeat}{}

\everymath=\expandafter{\the\everymath\displaystyle}
%%\usepackage{psfig}
\DeclareMathSizes{24}{24}{24}{24}
\newcommand{\lecture}[2]{
  \noindent
  \begin{center}
  \framebox{
    \vbox{
      \hbox to 5.78in { {\bf CS7140: Advanced Machine Learning} \hfill Spring 2025}
      \vspace{4mm}
      \hbox to 5.78in { {\Large \hfill #1  \hfill} }
      \vspace{2mm}
      \hbox to 5.78in { {\em Instructor: Ryan Zhang  \hfill Due: #2} }
    }
  }
  \end{center}
  \vspace*{4mm}
}
%\newcommand{\dim}{\textup{dim}}


\newcommand*{\diffdchar}{d}    % or {ⅆ}, or {\mathrm{d}}, or whatever standard you’d like to adhere to
\newcommand*{\dd}{\mathop{\diffdchar\!}}


\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{assumption}[theorem]{Assumption}

% 1-inch margins, from fullpage.sty by H.Partl, Version 2, Dec. 15, 1988.
\topmargin 0pt
\advance \topmargin by -\headheight
\advance \topmargin by -\headsep
\textheight 8.9in
\oddsidemargin 0pt
\evensidemargin \oddsidemargin
\marginparwidth 0.5in
\textwidth 6.5in

\parindent 0in
\parskip 1.5ex
%\renewcommand{\baselinestretch}{1.25}

\newcommand{\E}{\mathbb{E}}





\usepackage{amsmath, amssymb}
\usepackage{fullpage}
\pagestyle{empty}
\def\pp{\par\noindent}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\renewcommand{\baselinestretch}{1.2}
\newcommand{\problem}[1]{ \bigskip \pp \textbf{Problem #1}\par}
\newcommand{\solution}{\textit{Solution:}\par}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\bbZ}    {\mathbb{Z}}
\newcommand{\bbQ}    {\mathbb{Q}}
\newcommand{\bbN}    {\mathbb{N}}
\newcommand{\bbB}    {\mathbb{B}}
\newcommand{\bbR}    {\mathbb{R}}
\newcommand{\bbC}    {\mathbb{C}}
\newcommand{\calP}   {{\cal{P}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\lecture{Problem Set 1}{\textbf{Feb 5, 2025, 11:59pm}}

\textbf{Policy:} We encourage discussions and collaborations on homework. You should write up the solution independently and remember to mention any fellow students you collaborated with. There are up to three late days for all the problem sets and project submissions.
After that, the grade depreciates by 20\% for every extra day.
Late submissions are treated on a case by case basis. Please reach out to the instructor at \texttt{ho.zhang@northeastern.edu} to discuss.
All homework submissions are subject to the Northeastern University Honor Code.

\textbf{Submission:} We will use Gradescope for the homework submissions. Please submit your written solutions to Gradescope.
Login to Gradescope through Canvas using your northeastern.edu account.
For code submission, please print out the code file and attach it to the PDF solution file.
We strongly recommend that you write up your solution in LaTeX. For reference, you can find the LaTex source code at \url{https://github.com/hongyangsg/cs7140/tree/main/homeworks}.

\textbf{Length of submissions:} Include as much of the calculations needed to understand the answer. After solving the problem, try to identify the main steps taken and critical points of proof and include them as a rule of thumb.

\newpage
\paragraph{Problem 1 (15 points)}
Random Bits:
\begin{enumerate}[label=\alph*)]
    \item (5 points) Given access to coins whose probability of landing heads is $1/5$, describe a scheme for generating a uniformly random bit. In other words, how can one simulate a flip of a coin that lands heads with probability exactly $1/2$?
    \item (5 points) Given access to coins whose probability of landing heads is $1/2$, describe a scheme for simulating the flip of a coin whose probability of heads is $1/5$.
    \item (5 points) In one or two sentences, explain why the above problems are impossible if one is required to write a protocol that flips the given coins at most some finite number, $k$, times.
\end{enumerate}

\newpage
\paragraph{Problem 2 (15 points)}
After everyone aces the final exam, as a token of appreciation for being such good students, all $100$ of you are treated to lunch at Tatte Cafe, and everyone orders one out of $20$ possible lunch options. Unfortunately, due to some confusion, your orders were lost, and the chef uniformly at random picks the lunch to make for each student. For each of the following questions, please explain your answer with one or two sentences.
\begin{enumerate}[label=\alph*)]
    \item (5 points) What is the expected number of students who end up with the lunch they ordered? (Hint: linearity of expectation!)
    
    \item (5 points) If, instead of making a uniformly random lunch for each student, the chef first makes exactly $5$ lunches of each of the $20$ types, then randomly hands them out, what is the expected number of students who end up with the lunch they ordered? (Hint: linearity of expectation!)
    
    \item (5 points) In the original setting (where the chef picks one of the $20$ lunches at random for each student) what is the expected number of types of lunch that are made exactly once? Phrased differently, what is the expected number of students that get a unique lunch? (Hint: linearity of expectation!)
\end{enumerate}

\newpage
\paragraph{Problem 3 (20 points)}
Suppose $X$ and $Y$ are independent sub-Gaussian random variables with parameters $\sigma_x^2$ and $\sigma_y^2$. Show the following properties of sub-Gaussianity.
\begin{enumerate}[label=\alph*)]
    \item (10 points)  Scalar: Show that for any $c > 0$, $cX$ is sub-Gaussian with parameter $c^2\sigma_x^2$.

    \item (10 points)  Sum: Show that the sum of $X$ and $Y$ is sub-Gaussian with parameter $\sigma_x^2 + \sigma_y^2$.
\end{enumerate}

\newpage
\paragraph{Problem 4 (30 points)}
For a random variable $X$, recall that the moment generating function (MGF) of $X$ is defined as $M_X(t) = \mathbb{E}[e^{tX}]$.
In this problem, we consider the MGF of several commonly encountered distributions.
\begin{enumerate}[label=\alph*)]
    \item (10 points) Let $X\sim{\rm Poisson}(\lambda)$ be a Poission random variable with expectation $\lambda$. Show that the MGF of $X$ is $e^{\lambda(e^t - 1)}$. Recall that the probability density function of $X$ is $\frac{\lambda^k e^{-\lambda}}{k!}$ for any non-negative integer $k\in \mathbb{N}$.

    \item (10 points)  Let $X\sim{\rm  Bernoulli}(p)$ be a Bernoulli random variable that is equal to one with probability $p$ and zero otherwise. Show that the MGF of $X$ is $1 - p + e^t p$.

    \item (10 points)  Let $X$ is a continuous uniform distribution on the interval $[a,b]$. Show that the MGF of $X$ is $\frac{e^{tb} - e^{ta}}{t(b - a)}$ for $t \neq 0$.
\end{enumerate}

\newpage
\paragraph{Problem 5 (20 points)}
Tightness of Markov's and Chebyshev's inequalities, for all probability values:
\begin{enumerate}[label=\alph*)]
    \item (10 points) Prove that Markov's inequality is tight: show that for any $p\in [0, 1]$ and $a > 0$, there exists a random variable $X$, defined in terms of $p$ and $a$, that is always nonnegative, and for which $p = \Pr[X \ge a] = \frac{\ex{X}} {a}$.
    \item (10 points) Prove that Chebyshev's inequality is tight: show that for any $p \in [0, 1]$ and $a > 0$, there exists a random variable $X$ defined in terms of $p$ and $a$ for which $p = \Pr[\abs{X - \ex{X}} \ge a] = \frac{\Var{X}}{a^2}$.
\end{enumerate}
\end{document}